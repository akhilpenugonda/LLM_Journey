{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install semantic_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßë‚Äçüç≥ L1 - Semantic Kernel is like\u000byour AI cooking kitchen\n",
    "\n",
    "### üî• Get a kernel ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'T5ForConditionalGeneration' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You made an open source kernel using an open source AI model!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import semantic_kernel as sk\n",
    "from IPython.display import display, Markdown\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, OpenAIChatCompletion\n",
    "from semantic_kernel.connectors.ai.hugging_face import HuggingFaceTextCompletion\n",
    "\n",
    "# kernel = sk.Kernel()\n",
    "\n",
    "# useAzureOpenAI = False\n",
    "\n",
    "# if useAzureOpenAI:\n",
    "#     deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "#     kernel.add_text_completion_service(\"azureopenai\", AzureChatCompletion(deployment, endpoint, api_key))\n",
    "# else:\n",
    "#     api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "#     kernel.add_text_completion_service(\"openai\", OpenAIChatCompletion(\"gpt-3.5-turbo-0301\", api_key, org_id))\n",
    "\n",
    "# print(\"You made a kernel!\")\n",
    "\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "kernel.add_text_completion_service(\"huggingface\", HuggingFaceTextCompletion(\"EleutherAI/gpt-j-6B\", task=\"text-generation\"))\n",
    "\n",
    "\n",
    "print(\"You made an open source kernel using an open source AI model!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîñ Reminder: A kernel is like the stove in a kitchen. It doesn't do anything unless you start to cook with it. Let's proceed to get it a few functions to üî• cook up for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's make a semantic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A semantic function for summarization has been registered.\n"
     ]
    }
   ],
   "source": [
    "sk_prompt = \"\"\"\n",
    "{{$input}}\n",
    "\n",
    "Summarize the content above in less than 140 characters.\n",
    "\"\"\"\n",
    "summary_function = kernel.create_semantic_function(prompt_template = sk_prompt,\n",
    "                                                    description=\"Summarizes the input to length of an old tweet.\",\n",
    "                                                    max_tokens=200,\n",
    "                                                    temperature=0.1,\n",
    "                                                    top_p=0.5)       \n",
    "print(\"A semantic function for summarization has been registered.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_input = \"\"\"\n",
    "Let me illustrate an example. Many weekends, I drive a few minutes from my house to a local pizza store to buy \n",
    "a slice of Hawaiian pizza from the gentleman that owns this pizza store. And his pizza is great, but he always \n",
    "has a lot of cold pizzas sitting around, and every weekend some different flavor of pizza is out of stock. \n",
    "But when I watch him operate his store, I get excited, because by selling pizza, he is generating data. \n",
    "And this is data that he can take advantage of if he had access to AI.\n",
    "\n",
    "AI systems are good at spotting patterns when given access to the right data, and perhaps an AI system could spot \n",
    "if Mediterranean pizzas sell really well on a Friday night, maybe it could suggest to him to make more of it on a \n",
    "Friday afternoon. Now you might say to me, \"Hey, Andrew, this is a small pizza store. What's the big deal?\" And I \n",
    "say, to the gentleman that owns this pizza store, something that could help him improve his revenues by a few \n",
    "thousand dollars a year, that will be a huge deal to him.\n",
    "\"\"\"\n",
    "# Text source: https://www.ted.com/talks/andrew_ng_how_ai_could_empower_any_business/transcript\n",
    "\n",
    "summary_result = await kernel.run_async(summary_function, input_str=sk_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### ‚ú® \n",
       "\n",
       "Let me illustrate an example. Many weekends, I drive a few minutes from my house to a local pizza store to buy \n",
       "a slice of Hawaiian pizza from the gentleman that owns this pizza store. And his pizza is great, but he always \n",
       "has a lot of cold pizzas sitting around, and every weekend some different flavor of pizza is out of stock. \n",
       "But when I watch him operate his store, I get excited, because by selling pizza, he is generating data. \n",
       "And this is data that he can take advantage of if he had access to AI.\n",
       "\n",
       "AI systems are good at spotting patterns when given access to the right data, and perhaps an AI system could spot \n",
       "if Mediterranean pizzas sell really well on a Friday night, maybe it could suggest to him to make more of it on a \n",
       "Friday afternoon. Now you might say to me, \"Hey, Andrew, this is a small pizza store. What's the big deal?\" And I \n",
       "say, to the gentleman that owns this pizza store, something that could help him improve his revenues by a few \n",
       "thousand dollars a year, that will be a huge deal to him.\n",
       "\n",
       "\n",
       "Summarize the content above in less than 140 characters.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"### ‚ú® \" + str(summary_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
